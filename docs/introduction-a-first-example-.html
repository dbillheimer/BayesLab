<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>BayesLab - Exploring Bayesian Hierarchical Modeling and Predictive Inference</title>
  <meta name="description" content="Explores the use of Bayesian hierarchical modeling and predictive inference.">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="BayesLab - Exploring Bayesian Hierarchical Modeling and Predictive Inference" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://github.com/dbillheimer/BayesLab/" />
  
  <meta property="og:description" content="Explores the use of Bayesian hierarchical modeling and predictive inference." />
  <meta name="github-repo" content="dbillheimer/BayesLab" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="BayesLab - Exploring Bayesian Hierarchical Modeling and Predictive Inference" />
  
  <meta name="twitter:description" content="Explores the use of Bayesian hierarchical modeling and predictive inference." />
  

<meta name="author" content="Dean Billheimer">


<meta name="date" content="2018-07-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="prediction.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">BayesLab - Bayesian Hierarchical Modeling</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html"><i class="fa fa-check"></i><b>1</b> Introduction - A first example.</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#a-scientists-analysis"><i class="fa fa-check"></i><b>1.1</b> A Scientist’s Analysis</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#more-standard-classical-analysis"><i class="fa fa-check"></i><b>1.2</b> More Standard Classical Analysis</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#bayesian-hierarchical-modeling"><i class="fa fa-check"></i><b>1.3</b> Bayesian Hierarchical Modeling</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#estimating-the-a-effect"><i class="fa fa-check"></i><b>1.3.1</b> Estimating the A effect</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#ab-interaction"><i class="fa fa-check"></i><b>1.3.2</b> A:B Interaction</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-a-first-example-.html"><a href="introduction-a-first-example-.html#fundamental-problem"><i class="fa fa-check"></i><b>1.4</b> Fundamental Problem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prediction.html"><a href="prediction.html"><i class="fa fa-check"></i><b>2</b> Prediction</a><ul>
<li class="chapter" data-level="2.1" data-path="prediction.html"><a href="prediction.html#predicting-a-future-significant-result"><i class="fa fa-check"></i><b>2.1</b> Predicting a future ‘significant’ result</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">BayesLab - Exploring Bayesian Hierarchical Modeling and Predictive Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction---a-first-example." class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction - A first example.</h1>
<p>Suppose we have a simple experiment with two factors (A/B), each with two levels (aA, bB), conducted in a factorial design with <span class="math">\(n=10\)</span> observations per group. Our general hypothesis is that either factor A or factor B might increase the response, or that both together might be required to create an increase. Let’s consider some data (well, frauda = ‘fraudulent data’), for these four groups (shown below).</p>
<p><img src="datasim-1.png" width="576" style="display: block; margin: auto;" /></p>
<div id="a-scientists-analysis" class="section level2">
<h2><span class="header-section-number">1.1</span> A Scientist’s Analysis</h2>
<p>A typical “laboratory” analysis would consider group comparisons using <span class="math">\(t\)</span>-tests.</p>
<p>For ab vs. Ab</p>
<pre><code>
    Welch Two Sample t-test

data:  y[group == &quot;ab&quot;] and y[group == &quot;Ab&quot;]
t = -1.4267, df = 16.739, p-value = 0.1721
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -1.6205353  0.3139597
sample estimates:
mean of x mean of y 
 3.026748  3.680035 </code></pre>
<p>For ab vs. aB</p>
<pre><code>
    Welch Two Sample t-test

data:  y[group == &quot;ab&quot;] and y[group == &quot;aB&quot;]
t = -1.443, df = 17.057, p-value = 0.1671
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -1.6523020  0.3098862
sample estimates:
mean of x mean of y 
 3.026748  3.697956 </code></pre>
<p>and finally for ab vs. AB</p>
<pre><code>
    Welch Two Sample t-test

data:  y[group == &quot;ab&quot;] and y[group == &quot;AB&quot;]
t = -3.4484, df = 17.79, p-value = 0.002907
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
 -3.0392917 -0.7367985
sample estimates:
mean of x mean of y 
 3.026748  4.914793 </code></pre>
<p>A simple interpretation is that neither A (<span class="math">\(p =\)</span> 0.17) nor B (<span class="math">\(p =\)</span> 0.17) alone produce an increase, but A and B together ‘interact’ to create an increase in <span class="math">\(y\)</span>.</p>
<p><img src="stars-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Clearly, there are issues here. But note that even if I use a Bonferroni correction for multiple testing, the interaction p-value remains significant (<span class="math">\(p =\)</span> 0.009). I think many lab scientists would not see a huge problem here, and I’m pretty sure this could be published in a good journal.</p>
</div>
<div id="more-standard-classical-analysis" class="section level2">
<h2><span class="header-section-number">1.2</span> More Standard Classical Analysis</h2>
<p>A slightly different (better?) analysis considers the groups (and factors) together. This is the standard two-way factorial analysis. “Better” here, depends on your hypotheses. Results are shown in the tables below.</p>
<table>
<caption><span id="tab:anova">Table 1.1: </span>ANOVA for two-factor experiment</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a.fac</td>
<td align="right">1</td>
<td align="right">8.743</td>
<td align="right">8.743</td>
<td align="right">7.627</td>
<td align="right">0.009</td>
</tr>
<tr class="even">
<td align="left">b.fac</td>
<td align="right">1</td>
<td align="right">9.082</td>
<td align="right">9.082</td>
<td align="right">7.922</td>
<td align="right">0.008</td>
</tr>
<tr class="odd">
<td align="left">a.fac:b.fac</td>
<td align="right">1</td>
<td align="right">0.794</td>
<td align="right">0.794</td>
<td align="right">0.693</td>
<td align="right">0.411</td>
</tr>
<tr class="even">
<td align="left">Residuals</td>
<td align="right">36</td>
<td align="right">41.271</td>
<td align="right">1.146</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<pre><code>
Call:
lm(formula = y ~ a.fac * b.fac)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.00535 -0.73052  0.09802  0.71468  1.81550 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     3.0267     0.3386   8.939 1.14e-10 ***
a.facA          0.6533     0.4788   1.364    0.181    
b.facB          0.6712     0.4788   1.402    0.170    
a.facA:b.facB   0.5635     0.6772   0.832    0.411    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.071 on 36 degrees of freedom
Multiple R-squared:  0.3109,    Adjusted R-squared:  0.2535 
F-statistic: 5.414 on 3 and 36 DF,  p-value: 0.003531</code></pre>
<p>The “textbook” interpretation (from a second stats class) is there are significant A and B effects, but no A:B interaction (again, based on p-values). This is the exact opposite of the simple-approach analysis above. WTF! It’s not really fair to blame p-values for this, but their use doesn’t help the situation.</p>
<p>More carefully, the interpretaion can be complicated. If there is truly no interaction, then the A and B main effects are estimated efficiently using all observations, and we can conclude ‘significant A and B main effects’. The SS partitioning does not indicate a strong effect of the interaction. But zero? We know interaction tests often suffer from - low power - awkward interpretation - potential mismatch between scientific and statisitcal hypotheses</p>
<p>If you can’t rule out the interaction (e.g., via an equivalence test or similar), do you want to assume it is zero?</p>
<p>If an interaction is present, then clean estimation of the main effects is difficult. If the interaction is not assumed zero, Classical procedure reverts to pairwise comparisons of groups (and the simple scientist’s analysis is not far off).</p>
<p>Conversely, assuming no interaction is equivalent to accepting the interaction null hypothesis (a classical, knee-jerk no-no). Also, because the A:B interaction is part of the original hypothesis to be evaluated, this assumption seems problematic, or at least philosophically suspect.</p>
<p>Many of the issues here appear to result from a forced dichotomization or conditioning on intermediate results. Is the A:B interaction present or not? Conditional on this answer, we choose a next analysis procedure. Surely the conditional analysis must have an effect on Type I error rate. (It obviously effects Type II errors.)</p>
</div>
<div id="bayesian-hierarchical-modeling" class="section level2">
<h2><span class="header-section-number">1.3</span> Bayesian Hierarchical Modeling</h2>
<p>In the Bayesian approach, we compute posterior probabities of unknown quantities (here, means and variances).</p>
<p>Table  shows mean and quantile estimates of the group means.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kable</span>(mcmc.parEst, <span class="dt">booktabs=</span><span class="ot">TRUE</span>, <span class="dt">digits=</span><span class="dv">2</span>,
      <span class="dt">caption=</span><span class="st">&quot;Group mean estimates and quantiles from Bayesian model&quot;</span>)</code></pre>
<table>
<caption><span id="tab:outtable">Table 1.2: </span>Group mean estimates and quantiles from Bayesian model</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">mean</th>
<th align="right">2.5%</th>
<th align="right">10%</th>
<th align="right">50%</th>
<th align="right">90%</th>
<th align="right">97.5%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ab</td>
<td align="right">3.15</td>
<td align="right">2.47</td>
<td align="right">2.71</td>
<td align="right">3.15</td>
<td align="right">3.59</td>
<td align="right">3.82</td>
</tr>
<tr class="even">
<td align="left">Ab</td>
<td align="right">3.70</td>
<td align="right">3.06</td>
<td align="right">3.29</td>
<td align="right">3.69</td>
<td align="right">4.12</td>
<td align="right">4.32</td>
</tr>
<tr class="odd">
<td align="left">aB</td>
<td align="right">3.72</td>
<td align="right">3.08</td>
<td align="right">3.31</td>
<td align="right">3.71</td>
<td align="right">4.13</td>
<td align="right">4.35</td>
</tr>
<tr class="even">
<td align="left">AB</td>
<td align="right">4.74</td>
<td align="right">3.98</td>
<td align="right">4.28</td>
<td align="right">4.75</td>
<td align="right">5.21</td>
<td align="right">5.47</td>
</tr>
</tbody>
</table>
<p><img src="newfig-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Figure (fig:newfig} shows that Bayesian estimates ‘borrow’ strength’ across groups and are shrunk toward the overall mean of all groups. In this example, the Bayesian credible intervals are approximately the same length as the classical confidence intervals (about 0.980.980.980.98%). I also show Bayesian 80% posterior credible intervals. In general, these intervals are about 2/3 as long as 95% intervals, but still retain substantial posterior probability for the mean value (4 chances in 5, pretty good, que no?). IMO this narrower interval helps us focus on the quantities we care about.</p>
<div id="estimating-the-a-effect" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Estimating the A effect</h3>
<p>To estimate the effect of treatment A, let’s check its effect in the absense (b) and presence (B) of treatment B. Figure  shows estimated densities (distributions) for the mean difference associated with A when B is absent (black curve), and when B is present (red).</p>
<table>
<caption><span id="tab:A-effect">Table 1.3: </span>Mean effect of A treatment with and without B</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">mean</th>
<th align="right">2.5%</th>
<th align="right">10%</th>
<th align="right">50%</th>
<th align="right">90%</th>
<th align="right">97.5%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A - a w/ b</td>
<td align="right">0.55</td>
<td align="right">-0.41</td>
<td align="right">-0.07</td>
<td align="right">0.55</td>
<td align="right">1.17</td>
<td align="right">1.47</td>
</tr>
<tr class="even">
<td align="left">A - a w/ B</td>
<td align="right">1.02</td>
<td align="right">0.05</td>
<td align="right">0.38</td>
<td align="right">1.03</td>
<td align="right">1.65</td>
<td align="right">1.99</td>
</tr>
</tbody>
</table>
<p><img src="A-effect-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The figure shows that the curves are centered on mean estimates of 0.5, and 1, respectively, indicating (perhaps) a positive effect of A. When B is absent, the probability of no effect (or negative effect) is 0.12 and when B is present is 0.02. Combining curves (marginalizing over B) results in probability 0.07. To me these results suggest some (weakish) evidence of an A effect regardless of the level of B, and somwhat stronger evidence of an A effect in the presence of B.</p>
<p>What, specifically, was the original hypothesis about A and B? This clearly (now) has a bearing on our focus and interpretation.</p>
</div>
<div id="ab-interaction" class="section level3">
<h3><span class="header-section-number">1.3.2</span> A:B Interaction</h3>
<p>The conditional analysis in the previous subsection doesn’t directly address the A:B interaction. We’ll do that here.</p>
<p><img src="ABinter-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Figure  shows a density plot for the estimated interaction effect. The mean estimate is about 0.5, and the 80% interval ranges from about -0.4 to 1.4. Greater uncertainty associated with this effect reduces the evidence of a positive effect. The probability that the effect is zero (or negative) is 0.25.</p>
<p>The Bayesian analysis provides a similar interpretation of results as the factorial classical analysis. But, I think the focus on conditional pairwise comparisons makes it more palatable to non-statistical scientists. Here, the hierarchical modeling is used to address multiple comparisons issues (a la’ Gelman), but is not fundamental to the solution. It’s real benefit is to help us focus on effect sizes and interpretation of scientific hypotheses.</p>
</div>
</div>
<div id="fundamental-problem" class="section level2">
<h2><span class="header-section-number">1.4</span> Fundamental Problem</h2>
<p>I think the fundamental problem is with dichotomization of results and conditioning subsequent analyses on this choice. These are not conditional probabilities, but procedure choices that are conditional on earlier stage results.</p>
<p>BTW - what does interaction mean in this problem?</p>


</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="prediction.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
